{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlantBreed.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th4m1evM1aXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "e23adec2-22a4-4f93-d286-06964ae97ece"
      },
      "source": [
        "#Import necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from keras import applications\n",
        "from keras.models import Sequential, Model \n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import backend as k \n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBu92EpR1gEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qk6YDLf1iuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e22c2a88-9a2c-491d-ff49-53b59759f452"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUI5Pvcz1l3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "61b1cdfc-1730-4e30-ad5c-2d96696732a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcrZXIV-3Vy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFD8dEuA1pVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92d679d5-351b-4cf0-943a-d9e1d39b07cb"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/drive/My Drive/AIML/projects/NLP_Proj_2/train.zip', 'r') as trainfile:\n",
        "    trainfile.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-5-385242725bea>\", line 4, in <module>\n",
            "    trainfile.extractall()\n",
            "  File \"/usr/lib/python3.6/zipfile.py\", line 1524, in extractall\n",
            "    self._extract_member(zipinfo, path, pwd)\n",
            "  File \"/usr/lib/python3.6/zipfile.py\", line 1579, in _extract_member\n",
            "    shutil.copyfileobj(source, target)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 79, in copyfileobj\n",
            "    buf = fsrc.read(length)\n",
            "  File \"/usr/lib/python3.6/zipfile.py\", line 872, in read\n",
            "    data = self._read1(n)\n",
            "  File \"/usr/lib/python3.6/zipfile.py\", line 940, in _read1\n",
            "    data += self._read2(n - len(data))\n",
            "  File \"/usr/lib/python3.6/zipfile.py\", line 972, in _read2\n",
            "    data = self._fileobj.read(n)\n",
            "  File \"/usr/lib/python3.6/zipfile.py\", line 729, in read\n",
            "    data = self._file.read(n)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1452, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
            "    lines = linecache.getlines(file, globals_dict)\n",
            "  File \"/usr/lib/python3.6/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.6/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.6/tokenize.py\", line 454, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.6/tokenize.py\", line 423, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.6/tokenize.py\", line 381, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5QSDEqO18jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/drive/My Drive/AIML/projects/NLP_Proj_2/test.zip', 'r') as testfile:\n",
        "    testfile.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEaReP_h2FIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test=[]\n",
        "os.chdir('/content/drive/My Drive/AIML/projects/NLP_Proj_2/test')\n",
        "import cv2\n",
        "for i in os.listdir():\n",
        "    dummy = cv2.imread(i)\n",
        "    dummy = cv2.resize(dummy,(128,128))\n",
        "    x_test.append(dummy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOygHJAK2KEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "os.chdir('/content/drive/My Drive/AIML/projects/NLP_Proj_2/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qwpOCg22tIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "af703464-b004-4cc4-d89b-e16051da7dea"
      },
      "source": [
        "for i in os.listdir():\n",
        "    print(i)\n",
        "    if (os.path.isdir(i)):\n",
        "            for j in os.listdir(i):\n",
        "                try:\n",
        "                    dummy = cv2.imread('/content/drive/My Drive/AIML/projects/NLP_Proj_2/train/' + i + \"/\" + j)\n",
        "                    dummy = cv2.resize(dummy,(128,128))\n",
        "                    x_train.append(dummy)\n",
        "                    y_train.append(i)\n",
        "                except Exception as e:\n",
        "                    print(e)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fat Hen\n",
            "Small-flowered Cranesbill\n",
            "Cleavers\n",
            "Black-grass\n",
            "Sugar beet\n",
            "Shepherds Purse\n",
            "Charlock\n",
            "Loose Silky-bent\n",
            "Scentless Mayweed\n",
            "Maize\n",
            "Common Chickweed\n",
            "Common wheat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14F9G3FK22Qq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9db7380-bf42-4be6-826a-2828f133e39d"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuLIZS95_GGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dum = pd.get_dummies(y_train)\n",
        "encoded_labels = dum\n",
        "y_train = dum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud1YdKo7_PgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "x_train = np.array(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_jhbRAk_TWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36d6f2de-c9d8-49ba-ed9e-22a1cf4d137c"
      },
      "source": [
        "x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n",
        "print (len(x_train2))\n",
        "print (len(x_val))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3800\n",
            "950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgZnuA-y_Xoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshape the images\n",
        "x_train2 = x_train2.reshape(x_train2.shape[0],128,128,3)\n",
        "x_val = x_val.reshape(x_val.shape[0],128,128,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX8mXmPJ_a1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardize the images\n",
        "x_train2 = x_train2/255.\n",
        "x_val = x_val/255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYtE9GsD_eVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "82268191-3bec-46e0-b87c-f35fe1847a66"
      },
      "source": [
        "print (x_train2.shape, x_val.shape)\n",
        "print (y_train2.shape, y_val.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3800, 128, 128, 3) (950, 128, 128, 3)\n",
            "(3800, 12) (950, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGeR1WTH_jQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "28dade74-ec23-4d9c-da96-40cea274df02"
      },
      "source": [
        "#CNN Model\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalMaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Set the CNN model \n",
        "\n",
        "batch_size = None\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', batch_input_shape = (batch_size,128, 128, 3)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "\n",
        "model.add(GlobalMaxPooling2D())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(12, activation = \"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 32)      2432      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 32)      25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 12)                3084      \n",
            "=================================================================\n",
            "Total params: 341,036\n",
            "Trainable params: 341,036\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gq-8z0Y_zFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "784c9e8b-3fa3-45f0-a07c-51b7a589c94e"
      },
      "source": [
        "opt = Adam(lr=0.001)\n",
        "\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYy3W5S_AG3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "fed87e51-2705-41b8-ad08-206ab7af792d"
      },
      "source": [
        "model.fit(x_train, y_train, epochs = 10, validation_data = (x_val,y_val))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 4750 samples, validate on 950 samples\n",
            "Epoch 1/10\n",
            "4750/4750 [==============================] - 24s 5ms/step - loss: 13.9964 - acc: 0.1305 - val_loss: 2.4551 - val_acc: 0.1411\n",
            "Epoch 2/10\n",
            "4750/4750 [==============================] - 18s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.4551 - val_acc: 0.1411\n",
            "Epoch 3/10\n",
            "4750/4750 [==============================] - 17s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.5157 - val_acc: 0.1411\n",
            "Epoch 4/10\n",
            "4750/4750 [==============================] - 18s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.5157 - val_acc: 0.1411\n",
            "Epoch 5/10\n",
            "4750/4750 [==============================] - 17s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.5157 - val_acc: 0.1411\n",
            "Epoch 6/10\n",
            "4750/4750 [==============================] - 17s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.5157 - val_acc: 0.1411\n",
            "Epoch 7/10\n",
            "4750/4750 [==============================] - 17s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.5157 - val_acc: 0.1411\n",
            "Epoch 8/10\n",
            "4750/4750 [==============================] - 18s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.5157 - val_acc: 0.1411\n",
            "Epoch 9/10\n",
            "4750/4750 [==============================] - 18s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.5157 - val_acc: 0.1411\n",
            "Epoch 10/10\n",
            "4750/4750 [==============================] - 17s 4ms/step - loss: 13.8989 - acc: 0.1377 - val_loss: 2.5157 - val_acc: 0.1411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f24a4cda4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3QxvjXnB4r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}